Esta semana introduce los conceptos esenciales del Deep Learning, sentando las bases para la programación de redes neuronales y el entendimiento de sus aplicaciones.

### Conceptos Clave Cubiertos:

- **¿Qué es el Deep Learning y una Red Neuronal?**
    
    - El término "Deep Learning" se refiere al entrenamiento de redes neuronales, a veces muy grandes.
    - Una red neuronal se puede entender como la combinación de muchas "neuronas" simples apiladas.
    - Una única neurona puede implementar una función no lineal, como la función Rectified Linear Unit (ReLU), que devuelve cero para entradas negativas y una línea recta para entradas positivas, útil para predecir valores no negativos como precios de casas.
    - Las redes neuronales son particularmente útiles en entornos de aprendizaje supervisado, donde se busca mapear una entrada `X` a una salida `Y`.
    - La computación en una red neuronal se organiza en un **pase hacia adelante (forward pass)** para calcular las salidas y un **pase hacia atrás (backward pass)** para calcular los gradientes o derivadas.
- **Clasificación Binaria y Representación de Datos**
    
    - La **regresión logística** es un algoritmo para problemas de clasificación binaria, donde la etiqueta de salida `Y` es 0 o 1 (por ejemplo, reconocer si una imagen es un gato o no).
    - Las imágenes se representan como **vectores de características** `X` uniendo los valores de píxeles de los canales de color (Rojo, Verde, Azul). Una imagen de 64x64 píxeles tendría un vector `X` de 12288 dimensiones (64*64*3).
    - Un **ejemplo de entrenamiento** individual se representa como un par `(X, Y)`.
    - Un **conjunto de entrenamiento** se compone de `m` ejemplos.
    - Para una implementación más sencilla de redes neuronales, los ejemplos de entrenamiento `X` se apilan en columnas para formar una matriz `capital X` (de `nx` filas por `m` columnas), y las etiquetas `Y` también se apilan en columnas para formar una matriz `capital Y` (de 1 fila por `m` columnas).
    - La **capa de entrada** contiene las características de entrada `X`, también denotadas como `a^`.
    - Las **capas ocultas** son aquellas cuyos valores intermedios no se observan directamente en el conjunto de entrenamiento.
    - La **capa de salida** genera el valor predicho `Y_hat`, también denotado como `a^[L]` (para la última capa `L`).
    - Una red neuronal con una capa oculta se denomina una red neuronal de **dos capas** (no se cuenta la capa de entrada).
- **Regresión Logística: Un Modelo Básico**
    
    - El modelo de regresión logística predice `Y_hat`, la probabilidad de que `Y` sea 1, utilizando la **función sigmoide** aplicada a una combinación lineal de las entradas: `Y_hat = sigmoid(W.T * X + B)`.
    - La función sigmoide `sigmoid(Z) = 1 / (1 + e^-Z)` transforma un número real `Z` en un valor entre 0 y 1, lo que la hace adecuada para representar probabilidades.
    - Los **parámetros** del modelo son `W` (un vector de `nx` dimensiones) y `B` (un número real), los cuales se mantienen separados para facilitar la implementación.
- **Funciones de Pérdida y Costo**
    
    - Para entrenar los parámetros `W` y `B`, se necesita una **función de costo**.
    - La **función de pérdida (loss function)** `L(Y_hat, Y)` mide la calidad de la predicción `Y_hat` para un _único_ ejemplo de entrenamiento, comparándola con la etiqueta verdadera `Y`.
    - En regresión logística, la función de pérdida utilizada es `-Y log(Y_hat) - (1 - Y) log(1 - Y_hat)`. Esta elección garantiza un problema de optimización convexo, evitando múltiples mínimos locales.
    - La **función de costo (cost function)** `J(W, B)` es el promedio de las funciones de pérdida sobre _todos_ los `m` ejemplos de entrenamiento: `J = (1/m) * Sum(L(Y_hat_i, Y_i))`. El objetivo es encontrar `W` y `B` que minimicen `J`.
- **El Poder de las Redes Neuronales Profundas**
    
    - Las redes neuronales profundas (con muchas capas ocultas) pueden aprender funciones que los modelos más superficiales no pueden.
    - **Representaciones jerárquicas:** Las capas iniciales de una red profunda aprenden a detectar características más simples (ej. bordes en imágenes, características de onda en audio), y las capas posteriores componen estas características simples para detectar cosas más complejas (ej. partes de caras, palabras, frases).
    - Existe una analogía suelta con cómo el cerebro humano detecta primero cosas simples y luego las compone.
    - La **teoría de circuitos** sugiere que ciertas funciones (como XOR) son matemáticamente más fáciles de computar con redes profundas (log N capas) que con redes superficiales (requerirían exponencialmente más unidades ocultas).
- **Impulsores del Auge del Deep Learning**
    
    - El Deep Learning ha despegado recientemente debido a tres factores principales:
        - **Escala de Datos:** La gran cantidad de **datos etiquetados** disponibles (gracias a la digitalización y sensores) ha permitido que las redes neuronales grandes superen el rendimiento de los algoritmos tradicionales que se estancaban con más datos.
        - **Escala de Cómputo:** La capacidad de entrenar redes más grandes en **CPUs y GPUs** ha hecho posible aprovechar la gran cantidad de datos. Las innovaciones algorítmicas, como el cambio de funciones de activación sigmoide a ReLU, también han contribuido significativamente a la velocidad de cómputo al mitigar el problema de los gradientes que se desvanecen.
        - **Innovaciones Algorítmicas:** Avances como la función ReLU han permitido que algoritmos como el descenso de gradiente trabajen mucho más rápido. Esto acelera el ciclo de experimentación (ideas, implementación, ejecución, análisis, mejora), permitiendo a investigadores y practicantes iterar y mejorar los modelos más rápidamente.
- **Conceptos de Implementación Clave**
    
    - **Vectorización:** Es el arte de eliminar los bucles explícitos (`for loops`) en el código, lo que es crucial para la eficiencia en el Deep Learning, especialmente con grandes conjuntos de datos. Las operaciones vectorizadas aprovechan la paralelización inherente en CPUs y GPUs (instrucciones SIMD).
    - **Parámetros vs. Hiperparámetros:**
        - Los **parámetros** del modelo son `W` y `B`, los valores que el algoritmo aprende.
        - Los **hiperparámetros** son valores que se deben establecer _antes_ de entrenar el algoritmo y que controlan cómo se aprenden los parámetros. Incluyen la tasa de aprendizaje (`alpha`), el número de iteraciones, el número de capas ocultas (`L`), el número de unidades en cada capa (`n^[l]`), y la elección de la función de activación.
        - La aplicación del Deep Learning es un proceso empírico que requiere probar y ajustar muchos hiperparámetros para encontrar los mejores valores.
