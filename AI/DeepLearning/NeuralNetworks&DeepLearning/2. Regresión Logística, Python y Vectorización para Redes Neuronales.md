Esta semana profundiza en los fundamentos de la programación de redes neuronales, utilizando la regresión logística como un modelo introductorio y destacando la importancia crítica de la vectorización para una implementación eficiente.

---

### **Bloque 1: Regresión Logística como Red Neuronal**

La regresión logística, aunque simple, puede ser vista como la forma más básica o una **red neuronal de "una capa"**. Sirve como una excelente base para entender los bloques de construcción de redes más complejas.

- **Modelo de Regresión Logística:**
    
    - Para un ejemplo de entrenamiento dado ($X$), la regresión logística busca predecir una salida binaria ($Y$ es 0 o 1).
    - La predicción ($\hat{Y}$ o $A$) se calcula mediante la **función sigmoide** aplicada a una combinación lineal de las entradas.
    - **Fórmula:**
        - $Z = W^T X + B$
        - $A = \text{sigmoid}(Z)$
    - Donde $W$ son los pesos (un vector $N_x$ dimensional) y $B$ es el sesgo (un número real). La función sigmoide comprime el valor $Z$ entre 0 y 1, interpretándose como la probabilidad de que $Y=1$.
- **Función de Costo (Loss Function y Cost Function):**
    
    - Para entrenar el modelo, se necesita una función para medir qué tan bien se está desempeñando.
    - La **función de pérdida (loss function)** ($L(A, Y)$) mide el error para un **único ejemplo** de entrenamiento.
    - Para la regresión logística, se utiliza una función de pérdida que es **convexa**, lo que facilita la optimización con descenso de gradiente, a diferencia del error cuadrático que resultaría en un problema no convexo.
    - **Fórmula de la Función de Pérdida (para un solo ejemplo):**
        - $L(A, Y) = -Y \log(A) - (1-Y) \log(1-A)$
    - La **función de costo (cost function)** ($J(W, B)$) es el **promedio de las funciones de pérdida** sobre todo el conjunto de entrenamiento de $M$ ejemplos.
    - **Fórmula de la Función de Costo (para $M$ ejemplos):**
        - $J(W, B) = \frac{1}{M} \sum_{i=1}^{M} L(A^{(i)}, Y^{(i)})$
    - El objetivo es encontrar los parámetros $W$ y $B$ que **minimizan** esta función de costo.
- **Pase Hacia Adelante (Forward Propagation):**
    
    - Consiste en calcular las predicciones $A$ (o $\hat{Y}$) dado el $X$ de entrada y los parámetros $W$ y $B$.
- **Pase Hacia Atrás (Backward Propagation / Retropropagación):**
    
    - El objetivo es calcular los **gradientes** de la función de costo ($J$) con respecto a los parámetros $W$ y $B$. Estos gradientes indican la dirección de **descenso más pronunciado** para minimizar $J$.
    - Se utiliza la **regla de la cadena** del cálculo para derivar estas ecuaciones, propagando el error desde la salida hacia atrás.
    - **Notación para gradientes:** Se usa $dVariable$ (ej., $dZ$, $dA$, $dW$, $dB$) para denotar la derivada de la función de costo ($J$) con respecto a *Variable*.
    - **Fórmulas Clave para Retropropagación (para un solo ejemplo de Regresión Logística):**
        - $dA = -\frac{Y}{A} + \frac{1-Y}{1-A}$ (derivada de la pérdida con respecto a $A$)
        - $dZ = A - Y$ (derivada de la pérdida con respecto a $Z$, combinando $dA$ y la derivada de la sigmoide $g'(Z) = A(1-A)$)
        - $dW = X \cdot dZ$
        - $dB = dZ$
- **Descenso de Gradiente:**
    
    - Una vez calculados los gradientes ($dW$, $dB$), los parámetros se actualizan repetidamente para minimizar la función de costo.
    - **Reglas de Actualización:**
        - $W := W - \alpha \cdot dW$
        - $B := B - \alpha \cdot dB$
    - Donde $\alpha$ es la **tasa de aprendizaje (learning rate)**, un **hiperparámetro** que controla el tamaño del paso en cada actualización.
    - El descenso de gradiente es un proceso **iterativo**, que requiere múltiples pasos de propagación hacia adelante y hacia atrás.

---

### **Bloque 2: Python y Vectorización**

La eficiencia es crucial en el Deep Learning debido a los grandes volúmenes de datos. La **vectorización** es la técnica clave para lograr esta eficiencia en Python y NumPy.

- **La Importancia de la Vectorización:**
    
    - Consiste en **eliminar los bucles `for` explícitos** en el código.
    - NumPy y Python aprovechan las **instrucciones SIMD** (Single Instruction Multiple Data) y la paralelización en CPUs y GPUs para realizar operaciones matriciales y vectoriales de forma mucho más rápida que los bucles `for` tradicionales.
    - Puede acelerar el código **cientos de veces**.
    - En la era del Deep Learning, la vectorización ha pasado de ser un "lujo" a una **habilidad esencial** debido a los datasets cada vez más grandes.
- **Vectorización de la Propagación Hacia Adelante (para $M$ Ejemplos):**
    
    - En lugar de procesar un ejemplo de entrenamiento a la vez en un bucle `for`, se apilan todos los ejemplos horizontalmente en **matrices grandes**.
    - **Matriz de Entradas $X$ :** Los vectores de características $X^{(i)}$ de cada ejemplo se apilan como columnas, formando una matriz de dimensión $N_x \times M$.
    - **Matriz de Salidas $Y$ :** Similarmente, las etiquetas $Y^{(i)}$ se apilan en una matriz $1 \times M$.
    - Las ecuaciones de propagación hacia adelante se mantienen casi idénticas, pero ahora operan sobre matrices:
        - $Z^{[l]} = W^{[l]} A^{[l-1]} + B^{[l]}$
        - $A^{[l]} = G^{[l]}(Z^{[l]})$
    - $Z^{[l]}$ y $A^{[l]}$ se convierten en matrices de dimensión $n^{[l]} \times M$ (donde $n^{[l]}$ es el número de unidades en la capa $l$). Cada columna de estas matrices corresponde a un ejemplo de entrenamiento.
    - Para la adición del término de sesgo $B^{[l]}$ (que es un vector $n^{[l]} \times 1$) a la matriz $W^{[l]} A^{[l-1]}$ (que es $n^{[l]} \times M$), Python/NumPy utiliza el **broadcasting**. Esto significa que $B^{[l]}$ se "expande" implícitamente a una matriz de $n^{[l]} \times M$ duplicando sus columnas para que la suma sea posible.
    - A pesar de la vectorización, la propagación hacia adelante en una red profunda **sí requiere un bucle `for` explícito que itere sobre las capas** (de 1 a $L$). No hay una forma conocida de eliminar este bucle.
- **Vectorización de la Propagación Hacia Atrás (para $M$ Ejemplos):**
    
    - Los gradientes también se vectorizan, calculando $dZ$, $dA$, $dW$ y $dB$ para todos los ejemplos simultáneamente.
    - **Fórmulas Clave Vectorizadas para Redes Neuronales de dos capas (ejemplo):**
        - **Capa de Salida (Capa 2):**
            - $dZ^{} = A^{} - Y$
            - $dW^{} = \frac{1}{M} A^{} (dZ^{})^T$ (En la práctica, puede ser $X (dZ^{})^T$ si $A^{}$ es la capa de entrada)
            - $dB^{} = \frac{1}{M} \text{np.sum}(dZ^{}, \text{axis}=1, \text{keepdims}=\text{True})$ (para sumar las columnas de $dZ^{}$ y mantener la dimensión)
        - **Capa Oculta (Capa 1):**
            - $dZ^{} = (W^{})^T dZ^{} \odot G'^{}(Z^{})$ (El $\odot$ es un producto elemento a elemento)
            - $dW^{} = \frac{1}{M} X (dZ^{})^T$ (o $A^{} (dZ^{})^T$)
            - $dB^{} = \frac{1}{M} \text{np.sum}(dZ^{}, \text{axis}=1, \text{keepdims}=\text{True})$
    - Al igual que en la propagación hacia adelante, la retropropagación en una red profunda también **requiere un bucle `for` que itere sobre las capas** (de $L$ a 1).
- **Funciones de Activación:**
    
    - Introducen **no-linealidad** en la red. Sin ellas, una red profunda solo calcularía una función lineal, sin ser más expresiva que una regresión lineal.
    - **Sigmoide ($\sigma(Z) = 1 / (1 + e^{-Z})$):** Rango $[0, 1]$. Útil para la **capa de salida** en clasificación binaria. Su derivada es $A(1-A)$.
    - **Tanh ($\text{tanh}(Z) = (e^Z - e^{-Z}) / (e^Z + e^{-Z})$):** Rango $[-1, 1]$. Generalmente **mejor que la sigmoide para capas ocultas** porque centra la media de las activaciones más cerca de cero, facilitando el aprendizaje. Su derivada es $1 - A^2$.
    - **ReLU ($\text{max}(0, Z)$):** La elección por **defecto para capas ocultas**. Permite un aprendizaje más rápido ya que su derivada es 1 para $Z > 0$, lo que ayuda a mitigar el problema del gradiente desvanecido. Su derivada es 0 si $Z < 0$, 1 si $Z > 0$.
    - **Leaky ReLU ($\text{max}(0.01Z, Z)$):** Una variante de ReLU que tiene una pequeña pendiente para $Z < 0$, lo que puede prevenir "neuronas muertas". Su derivada es 0.01 si $Z < 0$, 1 si $Z > 0$.
    - Una **función de activación lineal** ($G(Z) = Z$) solo se usa en la **capa de salida** para problemas de regresión donde $Y$ es un valor real (ej., predicción de precios).
- **Inicialización de Parámetros:**
    
    - Es **crucial inicializar los pesos ($W$) de forma aleatoria** y con valores muy pequeños.
    - **No inicializar todos los pesos a cero:** Esto causa el **"problema de simetría"** (_symmetry breaking problem_), donde todas las unidades ocultas en la misma capa aprenderían la misma función y recibirían las mismas actualizaciones de gradiente, volviendo inútil tener múltiples unidades.
    - Inicializar con **valores pequeños** (ej., multiplicando por `0.01`) ayuda a evitar que las activaciones caigan en las regiones planas (de saturación) de las funciones sigmoide o tanh al inicio del entrenamiento, donde los gradientes son muy pequeños y el aprendizaje es lento.
    - Los sesgos ($B$) se pueden inicializar a cero sin problema.
- **Depuración y Prácticas de Código con NumPy:**
    
    - **Verificación de dimensiones de matrices:** Asegurarse de que las dimensiones de $W^{[l]}$, $B^{[l]}$, $Z^{[l]}$, $A^{[l]}$ y sus gradientes ($dW^{[l]}$, $dB^{[l]}$, $dZ^{[l]}$, $dA^{[l]}$) sean consistentes en cada operación es una herramienta clave para depurar errores.
        - $W^{[l]}$: $n^{[l]} \times n^{[l-1]}$
        - $B^{[l]}$: $n^{[l]} \times 1$
        - $X$ (o $A^{}$): $N_x \times M$
        - $Z^{[l]}$, $A^{[l]}$: $n^{[l]} \times M$
    - **Manejo de vectores en Python/NumPy:** Evitar los "rank-1 arrays" (ej., un vector `(5,)`) que pueden llevar a comportamientos no intuitivos en NumPy. Siempre definir explícitamente los vectores como vectores columna ($n \times 1$) o vectores fila ($1 \times n$) para un comportamiento consistente.
    - Usar afirmaciones (`assert`) para verificar las dimensiones de las matrices puede ayudar a detectar errores tempranamente.

---

Esta semana, a través de estos bloques, habrás aprendido a construir e implementar una red neuronal desde sus componentes más básicos, comprendiendo la lógica de las propagaciones hacia adelante y hacia atrás, y dominando las técnicas de vectorización esenciales para un código eficiente.